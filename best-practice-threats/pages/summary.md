## Recommendations

Each report section concludes with recommendations to different stakeholder for policies and activities that are aimed at minimising threats to human rights protection from the digital environment.

Additionally, on the basis of the analysis of the threats contained in the report, the following recommendations are made:

### Recommentations regarding overarching issues:

-    Consider recognizing **social media platforms as human rights duty-bearers.** The fact that social platforms are corporate entities and are in a position to cause enormous harm to human rights supports the need to recognize them as human rights duty-bearers. Since social platforms enjoy great power and no constitutional responsibility, it is high time to challenge the standard public/private division that still dominates constitutional law across the globe. 

-	**Develop specific** performance requirements (including human rights requirements) for investors **acting in the digital realm **

-    **Concerted action by civil society, governments and technology companies** is required to minimize the risks of social engineering attacks both to counter an improper cancellation and to prevent the use of personal information to illegally influence a person to vote for a particular candidate

-    Address the threat of Internet addiction by providing the **necessary health care services and taking preventive measures aimed at better online and offline time balance** inter alia by exploring the potential of a right to disconnect

-    Promote **ethical behaviour** and human rights in digital environment by means of **formal and non-formal education**

### Recommendations regarding threats connected to technology:

-    **Harmonized general rules regarding technological development must be established at the international level,** because potentially differing national approaches could lead to a significant weakening of the protection of fundamental human rights

-    A step-by-step legislative approach, based on the current state of technological development, having in mind the fast pace of technological progress in comparison to evolution of legal regulation, risks lagging far behind the technology, therefore it is important to **develop further legal requirements in relation to the use of AI and drones, focusing more on by-design / by-default measures and possible obligations for online service providers**

-	As not all potential risks of AI and drone applications are known or certain, **technological development (and legal regulation) should be based on the precautionary principle**

-	**AI and drones** should be designed to serve mankind and effectively **employed to help promote fundamental human rights**

-    A consistent, coherent and all-embracing body of **rules on automated decision-making needs to be formed clarifying liability issues**. States need to develop cooperation mechanisms towards ensuring that rules governing automated decision-making are properly implemented

-	Policymakers need to collaborate on **creating certification schemes (i.e. seals) and reporting mechanisms** to alleviate bias and other relevant problems. In addition, it is crucial that they work together on drawing up Codes of Conduct

### Recommendations regarding disinformation:

-	States have a duty under human rights law to protect their citizens from the harm caused by disinformation. In order to perform that duty, they need to **act together with other stakeholders such as transnational online media a**nd, in particular, very large online platforms

-    Action needs to be taken at global level to **limit the huge power large technology companies have over people and democracies.** The EU DSA could serve as a global benchmark for regulatory approaches to online intermediaries at the global level

-	Private content providers need well trained and supported content monitors in charge of scanning and deleting posts that violate clearly articulated platform guidelines. Such platforms should be required by law to ensure the validity of the information shared on them

-	If content providers do not address disinformation, states should work with other stakeholders to **identify and counter the disinformation before it can go viral or do significant harm**. This could be done through the creation of well-resourced units that would identify and respond to disinformation as required

-    Given the extremely harmful potential of disinformation, criminal prosecution should be considered where disinformation has caused particular harm or posed a particular threat

-    Anti-disinformation programmes need to constrain the state as well as private actors. The institutional design of the anti-disinfomation therefore needs to include **checks and balances to counter the power of both the state and big tech.** We recommend establishing expert units to monitor and analyse the distribution of information on social media. These teams should not be governmental units, but will need to work in conjunction with organs of state to handle crises and identify emerging threats

### Recommendations regarding threats connected to privacy and freedom of expression:

-	Data protection and privacy by design need to be at the core of new mobility services and facilitate human rights compliance whilst not hindering innovation

-    **Minimise shared responsibility among digital mobility providers** and clarify within the newly agreed Acts in Europe (e.g. MDMS, DSA) to improve enforcement.

-	Ensure that the same **human rights which exist in the physical products and services exist for digital products and services**, which should constitute a core principle across countries and transport modes as advocated by the GDHRNet

-    A delicate **regulatory balance is required in international and national law between mediating the public interest and individual rights online**. Law needs to set clear rules in which types of cases deplatforming could be considered a proportional measure

-	Decisions about deplatforming should be based on transparent rules and platforms should be required to provide a clear and specific **statement of reasons for the decision to suspend or block the account**

-	There need to be **procedural guarantees** – internet intermediaries should have a review procedure in place and there should be a possibility to seek judicial redress

-    **Clarifying criteria for RTBF need to be developed** in order to strike a fair balance among equally important competing values such as privacy and the freedom of expression

### Recommendations regarding vulnerable groups:

-    **Addressing the global digital divide is most appropriate within the framework of the United Nations** (ITU is particularly important in this field), as the United Nations deals with the topic most comprehensively; regional problems (e.g. related to internet speed and digital skills) should be dealt with in regional institutions

-    Digital skills development and training should be prioritised, with **special focus on educating vulnerable groups**

-    Efforts aimed at **regulating online speech should at least aim for regional, if not global cooperation**, since threats to vulnerable categories are usually cross-border in terms of their scope and effect

-    Policymakers and legislators, regulatory authorities (such as data protection and consumer protection authorities), industry, civil society and the research community must **work together to maximise the potential and minimise the threats that digital technologies pose to children and their rights**

-    **States should review, adopt and update national legislation to address the challenges for children’s rights, and conduct Children’s Rights Impact Assessments (CRIAs)** in the course of that process to ensure that the full range of children’s rights is taken into account in the digital environment

-    **Business actors in the digital sector also need to conduct CRIAs as part of child rights due diligence**, in order to identify and remedy the negative impact of their activities on children’s rights

-    To realise children’s rights in the digital environment, **awareness-raising, education and information about how digital technologies work should be provided** to professionals working with children, parents and children themselves. **Children should be involved** in the creation of such campaigns, learning material and information
