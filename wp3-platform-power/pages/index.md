
:-------------------- CHAPTER_HEADER --------------------:
image: "theme/images/bg_chapter.png"
authors: "Martin Fertmann, Matthias C. Kettemann, Thomas Wischmeyer and Torben Klausa"
title: European States and Platform Power 
subtitle: "What a Study of 15 European States Reveals about the Challenges of Governing Online Political Speech"
:---------------------------------------------------------:

## Introduction

In January, a great "deplatforming” took place: from January 6 onwards, Internet platforms like Twitter,[: REFERENCE | ref1 | :] Facebook and Instagram,[: REFERENCE | ref2 | :] YouTube[: REFERENCE | ref3 | :], Twitch[: REFERENCE | ref4 | :] and Snapchat[: REFERENCE | ref5 | :] removed the accounts and channels of Donald Trump and his supporters. But it wasn't just the top layer of the Internet – the platforms – that took action. Financial service providers such as Paypal, Venmo, GoFundMe and Stripe also kicked out Trump and his political supporters.[: REFERENCE | ref6 | :] The Conservative Facebook clone Parler was pushed out of Apple and Google's app stores[: REFERENCE | ref7 | :] and its data out of the cloud of Amazon's profitable data storage division. The reasoning in the latter case: Parler did not have sufficient internal rules against hate speech. Email service providers and even dating apps took similar action.

2021 thus began with an important realization: platforms can intervene (and remove content and users) very effectively if they want to. Even during the U.S. election campaign, they limited algorithmic recommendations, banned political ads, demonetized and deamplified problematic content. In general: 2020 was the year in which platforms (re)discovered that the fight against disinformation, especially in the context of the fight against Corona, also appeals to politicians and customers.

But if politicians themselves are at the core of the problem? Are platforms allowed to remove them? And what about political parties? If platforms should be allowed to act at least in certain circumstances, how exactly should these decisions be made within them in terms of deciders, processes, justifications and opportunities to appeal?

## The study

Across the world, societies continue to negotiate who the *least-worst* actor to control speech on the internet is, states or private platforms. The question of how to reign in harmful speech by government agencies or public office holders shines a light on the downsides of both approaches. State involvement in how official information is or is not disseminated by private actors is not only met with scepticism, but also subject to significant constitutional constraints in many countries. Vice-versa, the increase of platforms’ power over societal discourses that comes with them restricting democratically elected officeholders or determining the rules for political campaigns based on private terms of service is similarly hard to accept.

However, this Groundhog Day-esque discourse loop seems ready to be overcome through proposed new, hybrid actors such as independent “Social Media Councils”.[: REFERENCE | ref8 | :] Such institutions would be neither constructed exclusively from companies’ nor from states’ point of view but instead combine elements of external societal input with a degree of independence from both – states and companies.[: REFERENCE | ref9 | :]

The Facebook Oversight Board constitutes a first practical shot at creating such a structure and its decision[: REFERENCE | ref0 | :] on the question whether Trump should be allowed back was therefore unsurprisingly highly anticipated. In the end, the Oversight Board provided guidelines to re-examine the Trump ban, clarify their rules and the associated sanctions and to investigate what impact the company's own recommendation algorithms and user design had on the increased polarization of the American public and the storming of the U.S. Capitol on 6 January 2021.

Next to the question of “who decides”, the private regulation of public and political actors also provokes questions relating to the substantive justification for companies’ decisions. Social media companies have been deciding over the limits of expression of politicians, incumbents and other state actors on their platforms for years.

In principle, however, platforms provide exceptions for this group of people. Their statements therefore regularly remain available even in the case of violations of the terms of use and are, if at all, only equipped with a warning label.

Facebook for instance justifies this practice with the fact that there is a special public interest in the behavior of leading politicians and office holders (newsworthiness exemption). As a consequence, the company refrained from fact-checking posts by politicians in Germany in the past on the grounds that it "does *not* want to *interfere in the political discussion".*[: REFERENCE | ref1 | :] Twitter also privileges "*elected representatives and government officials*" because there is a considerable public interest in their contributions.[: REFERENCE | ref2 | :] This is always the case "*when (the posts) directly contribute to the understanding or discussion of a matter of public concern*".

However, the privileged treatment is not intended to apply across the board, but to function as a rule of thumb from which exceptions are possible. Twitter, for example, asserts that this "*(...) does not mean that a public official covered by this rule can tweet whatever he or she wants, even if it violates Twitter rules (...) \[Twitter\] balances the potential risk and severity of harm against the public interest in the tweet.* ”[: REFERENCE | ref3 | :]

While most platforms’ terms of use are global, opinions relating to the preferential treatment of speech by well-known political figures and office holders vary across national legal contexts. How can we as researchers navigate the interplay between global private rules of different platforms vis-à-vis a host of different national conceptions of the right balance between the integrity of political processes and companies’ rights to intervene on their platforms?

We are convinced that this can only be achieved through collective scientific action. This study therefore examines how private platform companies’ actions against public actors, including those taken in the U.S. against former president Trump, are perceived across different countries and shines a light on how a similar case would play out in the participating countries.

Through synthesizing answers to nine questions submitted by more than 30 researchers from 15 countries within the GDHR Network, this exploratory study provides a first overview of how societies and governments conceive of private power over political actors. This can also provide incentives for further rigorous studies of platforms’ actions against such actors and their impacts across different socio-cultural environments.

The individual submissions within this study are not intended to function as stand-alone, comprehensive assessments of the respective country. Rather, they function as pixels that collectively constitute a picture of an especially contested platform governance issue.

## The results

How did politicians, media and public opinion in the participating countries react to the suspensions and deletions of Trumps accounts from social networks?

It is important to note that the actions against Trump were not regarded as turning point in *all* participating countries, and moreover weren’t even publicly commented on by some countries’ politicians at all.[: REFERENCE | ref4 | :] This may not be unsurprising considering Trump was in fact not the first high-level politician whose content was restricted by internet platforms: These had previously acted against a Hungarian cabinet member,[: REFERENCE | ref5 | :] and the presidents of Brazil and Venezuela.[: REFERENCE | ref6 | :] The novelty in the Trump case therefore lay in the fact such a measure was directed against an (albeit: exiting) head of state from the global North.

In the majority of participating countries where the restrictions against Trump sparked a larger societal discussion, politicians concurred that the authority for the suspensions and deletions should not lie with the platforms,[: REFERENCE | ref7 | :] arriving not just at similar opinions but in part identical wording: Platforms’ actions were described as “problematic” by heads of government in Finland[: REFERENCE | ref8 | :] and Germany[: REFERENCE | ref9 | :] and even classified as “private censorship” by officials in Hungary[: REFERENCE | ref0 | :] and France[: REFERENCE | ref1 | :].

Such political statements often related the Trump case to freedom of expression, disregarding constitutional nuances such as that a) fundamental rights do not (or at least not directly) restrain private platforms and b) that public office holders can, in many countries, not invoke fundamental rights when acting in an official capacity.[: REFERENCE | ref2 | :] The actual question whether a holder of public office using an account partially in a private and partially in a public capacity (such as Trump) could invoke his or her right to freedom of expression against private restrictions (in line with doctrines of horizontal effects of fundamental rights) raises complex constitutional questions in most countries. The inapplicability, or degree of lowered protection due to the partially official use would need to be determined on a case-by-case basis across many participating countries.[: REFERENCE | ref3 | :]

The public outcry over private actors’ power to restrict the accessibility of the account of a public officeholder stands also in a notable discrepancy to the legal situation in all 15 participating countries, of which none reported a statutory obligation for social networks to disperse official information (something which might, notably, change, if the Digital Services Act enters into force unchanged, which provides for certain cooperation duties for very large platforms during emergencies. However, as the Corona crisis has shown us, platforms are very willing to offer privileged space for governmental actors communicating in their official capacity. If at all, such rules existed only with regard to TV and/or radio broadcasters and were predominantly limited to specific emergency cases.[: REFERENCE | ref4 | :]

In terms of political implications, media commentators viewed the step as a signal that far-right parties and politicians around the world may be acted against more strictly.[: REFERENCE | ref5 | :] Correspondingly, conservative politicians and governments in multiple countries instrumentalized the actions against Trump as supposed proof of platform’s bias against conservative opinions,[: REFERENCE | ref6 | :] a narrative that partially employed to justify new platform regulation initiatives that are presented to mitigate this supposed “bias”.[: REFERENCE | ref7 | :]

In fact, the accounts of far-right parties and their members *are* reported to be on the receiving end of a large share of platform actions such as content removals or account suspensions in multiple countries,[: REFERENCE | ref8 | :] although there is no indication that this would be the consequence of any kind of bias rather than the fact this part of the political spectrum posted a larger amount of content justifying such actions. Politicians who do face platform interventions use restrictions against their content in order to mobilize supporters and find other ways of disseminating restricted content, such as through third-party web sites collecting restricting content[: REFERENCE | ref9 | :] or disseminating it through messaging services.[: REFERENCE | ref0 | :]

Such divides (or “schisms”) that follow restrictions of content at major platforms are pointedly described through a historical comparison by an observer in Lithuania, assessing that both the excommunication from the church in Medieval times and the ban of accounts on social networks today can be taken swiftly, can be revoked upon repentance, are tough to challenge in court and may contribute to the creation of alternative institutions such as King Henry the VIII’s creation of the Church of England in 1534, following his excommunication by the Catholic church in 1533[: REFERENCE | ref1 | :] - or the joining of a rival social network.

Concerns by commentators from many countries over the implications of the moves against Trump for their countries, are emblematically captured by an Irish newspaper opinion stating that “*\[i\]f these newly-activist companies are prepared to take actions to stymie a sitting US president, imagine the political influence they could choose to exert, if it suited them, over a financially-puny State on the edge of Europe that badly needs their jobs, money and prestige?*”[: REFERENCE | ref2 | :] This, however, mistunderstands the special situation surrounding Donald Trump on and after 6 January with a view to his online communication practices. He had lost the election, was trying to steal it by encouraging his fans to fight and rebel. It would seem reasonable that a European politician in similar circumstances – say a presidential candidate who had lost and would act similarly – would also be – rightfully – banned.

When it comes to the respective legal framework, most of the surveyed countries do not have any laws or regulations that specifically cover restrictions by social networks against public actors such as public office holders or political parties.[: REFERENCE | ref3 | :] To some of the surveyed scholars, however, the topic touches broader constitutional provisions. This is the case in Italy, where the constitutional protection of political activities by members of parliament is “interpreted in a broad way and is not necessarily connected with activities performed within the Parliament” – and could potentially shield MP’s political content against moderation.[: REFERENCE | ref4 | :]

In some countries, possible implications of fundamental rights are also being discussed. While those rights usually apply as a legal defence of private actors against the state and *not* against other private entities,[: REFERENCE | ref5 | :] the responses from Germany and Ireland elaborate on the potential horizontal effect of constitutional rights in these countries. In the Irish case, a direct horizontal effect of the freedom of expression on private entities appears a mere theoretical option – without any existing case law.[: REFERENCE | ref6 | :] However, “it may be that the Irish courts could apply a doctrine of indirect horizontal effect in this context – for example, by interpreting terms of use or consumer protections against unfair contract terms in such a way as to promote freedom of expression rights against arbitrary interference by platforms.”[: REFERENCE | ref7 | :] A similar argument is made by the submission from Germany, where in specific cases the public position of the respective user can play a role in the necessary “weighing of the user’s fundamental rights (e.g., freedom of expression) against the rights of the private platform (e.g., property rights)” – but only, if the account is not an “official” state account, where fundamental rights do not apply.[: REFERENCE | ref8 | :]

Even without specific legal requirements on content moderation, submissions from several countries refer to a general – often: constitutional – privileging of speech of elected politicians and office holders. This could potentially support or even compel the decisions of platforms to leave content up even if it violates their terms of service.[: REFERENCE | ref9 | :] In contrast, some argue that in absence of any specific legal provisions the decision is completely left to the platforms.[: REFERENCE | ref0 | :] To many, however, this privileging and discretion only reaches as far as criminal law is not concerned.[: REFERENCE | ref1 | :] In general, the content moderation policy of big private actors like Facebook is sometimes seen as a “threat to our democracy,”[: REFERENCE | ref2 | :] although the reaction of – especially populist – parties and/or governments apparently depends on whether the private “censorship”[: REFERENCE | ref3 | :] is exerted in their favour or rather against them.[: REFERENCE | ref4 | :] As pointed out be the Greek submission, the whole situation calls for additional legislation.[: REFERENCE | ref5 | :] However, as the Irish assessment puts it, “it seems more likely that Irish law will be overtaken by developments at a European level and particularly the reforms proposed in the Digital Services Act.”[: REFERENCE | ref6 | :]

Another potential option for improving moderation practices is the implementation of “platform councils.” Such councils, staffed by representative citizens or experts, can function as advisory boards for platforms. While e.g. Facebook has implemented such a model with the Facebook Oversight Board, the discussion is picked up only in few of the surveyed countries.[: REFERENCE | ref7 | :] Instead, existing regulation for traditional media is often referenced as a possible role-model.[: REFERENCE | ref8 | :] Especially Broadcasting Councils are an institution that is known in most of the surveyed countries, although their compositions and influence on the program broadcast by public media differ.[: REFERENCE | ref9 | :]

The discussion about social media’s influence on public discourse, it seems, is just beginning. And although the de-platforming of Donald Trump might not have created the *reason* for said discussion: It has definitely been *cause* for the discussion to reach a broader audience.[: REFERENCE | ref0 | :]

:-------------------- CHAPTER_HEADER --------------------:
image: "theme/images/bg_chapter.png"
title: National Contributions 
subtitle: "Contributions by Question and Country"
:---------------------------------------------------------:

The survey preceeding this study was completed by experts from 15 countries. Their response to 12 questions and further material have been attached to this study in full length.

Please change to the tab [**National Contributions**](#contributions) to read all submissions.